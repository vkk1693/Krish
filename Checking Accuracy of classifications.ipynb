{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "news=pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>857</td>\n",
       "      <td>double eviction from big brother model caprice...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>325</td>\n",
       "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1590</td>\n",
       "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1587</td>\n",
       "      <td>apple ipod family expands market apple has exp...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>538</td>\n",
       "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "0          1833  worldcom ex-boss launches defence lawyers defe...   \n",
       "1           154  german business confidence slides german busin...   \n",
       "2          1101  bbc poll indicates economic gloom citizens in ...   \n",
       "3          1976  lifestyle  governs mobile choice  faster  bett...   \n",
       "4           917  enron bosses in $168m payout eighteen former e...   \n",
       "...         ...                                                ...   \n",
       "1485        857  double eviction from big brother model caprice...   \n",
       "1486        325  dj double act revamp chart show dj duo jk and ...   \n",
       "1487       1590  weak dollar hits reuters revenues at media gro...   \n",
       "1488       1587  apple ipod family expands market apple has exp...   \n",
       "1489        538  santy worm makes unwelcome visit thousands of ...   \n",
       "\n",
       "           Category  \n",
       "0          business  \n",
       "1          business  \n",
       "2          business  \n",
       "3              tech  \n",
       "4          business  \n",
       "...             ...  \n",
       "1485  entertainment  \n",
       "1486  entertainment  \n",
       "1487       business  \n",
       "1488           tech  \n",
       "1489           tech  \n",
       "\n",
       "[1490 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['source']=news.groupby('Category').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "group=news.groupby(['source', 'Category']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "group=group[['source','Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source       Category\n",
       "0       0       business\n",
       "1       1  entertainment\n",
       "2       2       politics\n",
       "3       3          sport\n",
       "4       4           tech"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=news.source\n",
    "x=news.drop('source',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "test=y_test.to_frame()\n",
    "train=y_train.to_frame()\n",
    "df_test=pd.merge(x_test, test, left_index=True, right_index=True)\n",
    "df_train=pd.merge(x_train, train, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def textcleaner_stem(Text): # Need Change here\n",
    "    \n",
    "    cleaner = re.sub(r\"[^a-zA-Z ]+\", ' ', Text.lower()) # Need Change here\n",
    "    cleaner = word_tokenize(cleaner)\n",
    "    ps = PorterStemmer()\n",
    "    clean = []\n",
    "    for w in cleaner:\n",
    "        if w not in stopWords:\n",
    "            if len(w)>2:\n",
    "                clean.append(ps.stem(w))\n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_text_stem'] = df_train.Text.apply(lambda x: textcleaner_stem(x))\n",
    "df_test['clean_text_stem'] = df_test.Text.apply(lambda x: textcleaner_stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def textcleaner_lemmas(Text): # Need Change here\n",
    "    cleaner = re.sub(r\"[^a-zA-Z ]+\", ' ', Text.lower()) # Need Change here\n",
    "    cleaner = word_tokenize(cleaner)\n",
    "    ps = PorterStemmer()\n",
    "    clean = []\n",
    "    for w in cleaner:\n",
    "        if w not in stopWords:\n",
    "            if len(w)>2:\n",
    "                clean.append(lemmatizer.lemmatize(w))\n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_text_lemma'] = df_train.Text.apply(lambda x: textcleaner_lemmas(x))\n",
    "df_test['clean_text_lemma'] = df_test.Text.apply(lambda x: textcleaner_lemmas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>clean_text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1108</td>\n",
       "      <td>blair stresses prosperity goals tony blair say...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>blair stress prosper goal toni blair say parti...</td>\n",
       "      <td>blair stress prosperity goal tony blair say pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1458</td>\n",
       "      <td>iranian misses israel match iranian striker va...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "      <td>iranian miss israel match iranian striker vahi...</td>\n",
       "      <td>iranian miss israel match iranian striker vahi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1913</td>\n",
       "      <td>elvis fans hold birthday bash elvis fans aroun...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>elvi fan hold birthday bash elvi fan around wo...</td>\n",
       "      <td>elvis fan hold birthday bash elvis fan around ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>11</td>\n",
       "      <td>berlin cheers for anti-nazi film a german movi...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>berlin cheer anti nazi film german movi anti n...</td>\n",
       "      <td>berlin cheer anti nazi film german movie anti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1055</td>\n",
       "      <td>vodafone appoints new japan boss vodafone has ...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>vodafon appoint new japan boss vodafon draft c...</td>\n",
       "      <td>vodafone appoints new japan bos vodafone draft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>253</td>\n",
       "      <td>ukip candidate suspended in probe eurosceptic ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>ukip candid suspend probe euroscept parti ukip...</td>\n",
       "      <td>ukip candidate suspended probe eurosceptic par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>4</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "      <td>yead face newcastl cup premiership side newcas...</td>\n",
       "      <td>yeading face newcastle cup premiership side ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1202</td>\n",
       "      <td>parmalat sues 45 banks over crash parmalat has...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>parmalat sue bank crash parmalat su bank tri r...</td>\n",
       "      <td>parmalat sue bank crash parmalat sued bank try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1114</td>\n",
       "      <td>satellite mapping aids darfur relief aid worke...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "      <td>satellit map aid darfur relief aid worker tri ...</td>\n",
       "      <td>satellite mapping aid darfur relief aid worker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>1239</td>\n",
       "      <td>sainsbury s labour election gift science minis...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>sainsburi labour elect gift scienc minist lord...</td>\n",
       "      <td>sainsbury labour election gift science ministe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1192 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "1103       1108  blair stresses prosperity goals tony blair say...   \n",
       "85         1458  iranian misses israel match iranian striker va...   \n",
       "1162       1913  elvis fans hold birthday bash elvis fans aroun...   \n",
       "614          11  berlin cheers for anti-nazi film a german movi...   \n",
       "77         1055  vodafone appoints new japan boss vodafone has ...   \n",
       "...         ...                                                ...   \n",
       "940         253  ukip candidate suspended in probe eurosceptic ...   \n",
       "922           4  yeading face newcastle in fa cup premiership s...   \n",
       "876        1202  parmalat sues 45 banks over crash parmalat has...   \n",
       "726        1114  satellite mapping aids darfur relief aid worke...   \n",
       "548        1239  sainsbury s labour election gift science minis...   \n",
       "\n",
       "           Category  source  \\\n",
       "1103       politics       2   \n",
       "85            sport       3   \n",
       "1162  entertainment       1   \n",
       "614   entertainment       1   \n",
       "77         business       0   \n",
       "...             ...     ...   \n",
       "940        politics       2   \n",
       "922           sport       3   \n",
       "876        business       0   \n",
       "726            tech       4   \n",
       "548        politics       2   \n",
       "\n",
       "                                        clean_text_stem  \\\n",
       "1103  blair stress prosper goal toni blair say parti...   \n",
       "85    iranian miss israel match iranian striker vahi...   \n",
       "1162  elvi fan hold birthday bash elvi fan around wo...   \n",
       "614   berlin cheer anti nazi film german movi anti n...   \n",
       "77    vodafon appoint new japan boss vodafon draft c...   \n",
       "...                                                 ...   \n",
       "940   ukip candid suspend probe euroscept parti ukip...   \n",
       "922   yead face newcastl cup premiership side newcas...   \n",
       "876   parmalat sue bank crash parmalat su bank tri r...   \n",
       "726   satellit map aid darfur relief aid worker tri ...   \n",
       "548   sainsburi labour elect gift scienc minist lord...   \n",
       "\n",
       "                                       clean_text_lemma  \n",
       "1103  blair stress prosperity goal tony blair say pa...  \n",
       "85    iranian miss israel match iranian striker vahi...  \n",
       "1162  elvis fan hold birthday bash elvis fan around ...  \n",
       "614   berlin cheer anti nazi film german movie anti ...  \n",
       "77    vodafone appoints new japan bos vodafone draft...  \n",
       "...                                                 ...  \n",
       "940   ukip candidate suspended probe eurosceptic par...  \n",
       "922   yeading face newcastle cup premiership side ne...  \n",
       "876   parmalat sue bank crash parmalat sued bank try...  \n",
       "726   satellite mapping aid darfur relief aid worker...  \n",
       "548   sainsbury labour election gift science ministe...  \n",
       "\n",
       "[1192 rows x 6 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=6, strip_accents='ascii', analyzer='word', lowercase=True,\n",
    "                             ngram_range=(1,2))\n",
    "\n",
    "x_train_stem = vectorizer.fit_transform(df_train['clean_text_stem'])\n",
    "y_train_stem = df_train['source']\n",
    "x_test_stem = vectorizer.transform(df_test['clean_text_stem'])\n",
    "y_test_stem = df_test['source']\n",
    "features_train = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Initialize and fit\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_stem, y_train_stem)\n",
    "\n",
    "# Apply to testing data\n",
    "y_pred_stem = nb.predict(x_test_stem)\n",
    "\n",
    "\n",
    "# Showing model performance\n",
    "print(\"Accuracy is: %0.3f\" % nb.score(x_test_stem, y_test_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6376"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=6, strip_accents='ascii', analyzer='word', lowercase=True,\n",
    "                             ngram_range=(1,2))\n",
    "\n",
    "x_train_lemma = vectorizer.fit_transform(df_train['clean_text_lemma'])\n",
    "y_train_lemma = df_train['source']\n",
    "x_test_lemma = vectorizer.transform(df_test['clean_text_lemma'])\n",
    "y_test_lemma = df_test['source']\n",
    "features_train = vectorizer.get_feature_names()\n",
    "len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "#Initialize and fit\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_lemma, y_train_lemma)\n",
    "\n",
    "# Apply to testing data\n",
    "y_pred_lemma = nb.predict(x_test_lemma)\n",
    "\n",
    "\n",
    "# Showing model performance\n",
    "print(\"Accuracy is: %0.3f\" % nb.score(x_test_lemma, y_test_lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  x_train_lemma\n",
    "Y_train = y_train_lemma\n",
    "X_test = x_test_lemma \n",
    "Y_test = y_test_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.970\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Create instance and fit\n",
    "sv = SVC(kernel='linear')\n",
    "sv.fit(X_train, Y_train)\n",
    "\n",
    "# Apply to testing data\n",
    "y_pred = sv.predict(X_test)\n",
    "\n",
    "# Showing model performance\n",
    "cross = pd.crosstab(y_pred, Y_test)\n",
    "print(\"Accuracy is: %0.3f\" % sv.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predict']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>1113</td>\n",
       "      <td>moya clinches cup for spain spain won the davi...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "      <td>moya clinch cup spain spain davi cup second ti...</td>\n",
       "      <td>moya clinch cup spain spain davis cup second t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>730</td>\n",
       "      <td>mansfield 0-1 leyton orient an second-half goa...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "      <td>mansfield leyton orient second half goal andi ...</td>\n",
       "      <td>mansfield leyton orient second half goal andy ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1483</td>\n",
       "      <td>youssou n dour wins music prize senegalese mus...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>youssou dour win music prize senegales musicia...</td>\n",
       "      <td>youssou dour win music prize senegalese musici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1547</td>\n",
       "      <td>hewitt overcomes wobble in sydney lleyton hewi...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "      <td>hewitt overcom wobbl sydney lleyton hewitt gav...</td>\n",
       "      <td>hewitt overcomes wobble sydney lleyton hewitt ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>2054</td>\n",
       "      <td>domain system opens door to scams a system to ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "      <td>domain system open door scam system make easie...</td>\n",
       "      <td>domain system open door scam system make easie...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>204</td>\n",
       "      <td>how to make a gigapixel picture the largest di...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "      <td>make gigapixel pictur largest digit panoram ph...</td>\n",
       "      <td>make gigapixel picture largest digital panoram...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>934</td>\n",
       "      <td>mutant book wins guardian prize a book about t...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>mutant book win guardian prize book evolut mut...</td>\n",
       "      <td>mutant book win guardian prize book evolution ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>213</td>\n",
       "      <td>chepkemei joins edinburgh line-up susan chepke...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "      <td>chepkemei join edinburgh line susan chepkemei ...</td>\n",
       "      <td>chepkemei join edinburgh line susan chepkemei ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>2015</td>\n",
       "      <td>desailly backs blues revenge trip marcel desai...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "      <td>desailli back blue reveng trip marcel desailli...</td>\n",
       "      <td>desailly back blue revenge trip marcel desaill...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1081</td>\n",
       "      <td>outkast win at mtv europe awards us hip-hop du...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>outkast win mtv europ award hip hop duo outkas...</td>\n",
       "      <td>outkast win mtv europe award hip hop duo outka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "1132       1113  moya clinches cup for spain spain won the davi...   \n",
       "669         730  mansfield 0-1 leyton orient an second-half goa...   \n",
       "408        1483  youssou n dour wins music prize senegalese mus...   \n",
       "20         1547  hewitt overcomes wobble in sydney lleyton hewi...   \n",
       "613        2054  domain system opens door to scams a system to ...   \n",
       "...         ...                                                ...   \n",
       "927         204  how to make a gigapixel picture the largest di...   \n",
       "1284        934  mutant book wins guardian prize a book about t...   \n",
       "1139        213  chepkemei joins edinburgh line-up susan chepke...   \n",
       "1111       2015  desailly backs blues revenge trip marcel desai...   \n",
       "1011       1081  outkast win at mtv europe awards us hip-hop du...   \n",
       "\n",
       "           Category  source  \\\n",
       "1132          sport       3   \n",
       "669           sport       3   \n",
       "408   entertainment       1   \n",
       "20            sport       3   \n",
       "613            tech       4   \n",
       "...             ...     ...   \n",
       "927            tech       4   \n",
       "1284  entertainment       1   \n",
       "1139          sport       3   \n",
       "1111          sport       3   \n",
       "1011  entertainment       1   \n",
       "\n",
       "                                        clean_text_stem  \\\n",
       "1132  moya clinch cup spain spain davi cup second ti...   \n",
       "669   mansfield leyton orient second half goal andi ...   \n",
       "408   youssou dour win music prize senegales musicia...   \n",
       "20    hewitt overcom wobbl sydney lleyton hewitt gav...   \n",
       "613   domain system open door scam system make easie...   \n",
       "...                                                 ...   \n",
       "927   make gigapixel pictur largest digit panoram ph...   \n",
       "1284  mutant book win guardian prize book evolut mut...   \n",
       "1139  chepkemei join edinburgh line susan chepkemei ...   \n",
       "1111  desailli back blue reveng trip marcel desailli...   \n",
       "1011  outkast win mtv europ award hip hop duo outkas...   \n",
       "\n",
       "                                       clean_text_lemma  predict  \n",
       "1132  moya clinch cup spain spain davis cup second t...        3  \n",
       "669   mansfield leyton orient second half goal andy ...        3  \n",
       "408   youssou dour win music prize senegalese musici...        1  \n",
       "20    hewitt overcomes wobble sydney lleyton hewitt ...        3  \n",
       "613   domain system open door scam system make easie...        4  \n",
       "...                                                 ...      ...  \n",
       "927   make gigapixel picture largest digital panoram...        4  \n",
       "1284  mutant book win guardian prize book evolution ...        1  \n",
       "1139  chepkemei join edinburgh line susan chepkemei ...        3  \n",
       "1111  desailly back blue revenge trip marcel desaill...        3  \n",
       "1011  outkast win mtv europe award hip hop duo outka...        1  \n",
       "\n",
       "[298 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "# Showing model performance\n",
    "cross = pd.crosstab(y_pred, Y_test)\n",
    "print(\"Accuracy is: %0.3f\" % lr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.940\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc.fit(X_train, Y_train)\n",
    "\n",
    "pred = gbc.predict(X_test)\n",
    "\n",
    "# Showing model performance\n",
    "cross = pd.crosstab(y_pred, Y_test)\n",
    "print(\"Accuracy is: %0.3f\" % gbc.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.960\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "# Showing model performance\n",
    "cross = pd.crosstab(y_pred, Y_test)\n",
    "print(\"Accuracy is: %0.3f\" % rfc.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
